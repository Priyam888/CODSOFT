{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfb4a687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63b11ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b9e299c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0            892         0       3   \n",
       "1            893         1       3   \n",
       "2            894         0       2   \n",
       "3            895         0       3   \n",
       "4            896         1       3   \n",
       "..           ...       ...     ...   \n",
       "413         1305         0       3   \n",
       "414         1306         1       1   \n",
       "415         1307         0       3   \n",
       "416         1308         0       3   \n",
       "417         1309         0       3   \n",
       "\n",
       "                                             Name     Sex   Age  SibSp  Parch  \\\n",
       "0                                Kelly, Mr. James    male  34.5      0      0   \n",
       "1                Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
       "2                       Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
       "3                                Wirz, Mr. Albert    male  27.0      0      0   \n",
       "4    Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
       "..                                            ...     ...   ...    ...    ...   \n",
       "413                            Spector, Mr. Woolf    male   NaN      0      0   \n",
       "414                  Oliva y Ocana, Dona. Fermina  female  39.0      0      0   \n",
       "415                  Saether, Mr. Simon Sivertsen    male  38.5      0      0   \n",
       "416                           Ware, Mr. Frederick    male   NaN      0      0   \n",
       "417                      Peter, Master. Michael J    male   NaN      1      1   \n",
       "\n",
       "                 Ticket      Fare Cabin Embarked  \n",
       "0                330911    7.8292   NaN        Q  \n",
       "1                363272    7.0000   NaN        S  \n",
       "2                240276    9.6875   NaN        Q  \n",
       "3                315154    8.6625   NaN        S  \n",
       "4               3101298   12.2875   NaN        S  \n",
       "..                  ...       ...   ...      ...  \n",
       "413           A.5. 3236    8.0500   NaN        S  \n",
       "414            PC 17758  108.9000  C105        C  \n",
       "415  SOTON/O.Q. 3101262    7.2500   NaN        S  \n",
       "416              359309    8.0500   NaN        S  \n",
       "417                2668   22.3583   NaN        C  \n",
       "\n",
       "[418 rows x 12 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "189af757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0          892         0       3   \n",
       "1          893         1       3   \n",
       "2          894         0       2   \n",
       "3          895         0       3   \n",
       "4          896         1       3   \n",
       "\n",
       "                                           Name     Sex   Age  SibSp  Parch  \\\n",
       "0                              Kelly, Mr. James    male  34.5      0      0   \n",
       "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
       "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
       "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
       "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
       "\n",
       "    Ticket     Fare Cabin Embarked  \n",
       "0   330911   7.8292   NaN        Q  \n",
       "1   363272   7.0000   NaN        S  \n",
       "2   240276   9.6875   NaN        Q  \n",
       "3   315154   8.6625   NaN        S  \n",
       "4  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ac589ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>417.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>2.265550</td>\n",
       "      <td>30.272590</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.392344</td>\n",
       "      <td>35.627188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>120.810458</td>\n",
       "      <td>0.481622</td>\n",
       "      <td>0.841838</td>\n",
       "      <td>14.181209</td>\n",
       "      <td>0.896760</td>\n",
       "      <td>0.981429</td>\n",
       "      <td>55.907576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>892.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>996.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1204.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   418.000000  418.000000  418.000000  332.000000  418.000000   \n",
       "mean   1100.500000    0.363636    2.265550   30.272590    0.447368   \n",
       "std     120.810458    0.481622    0.841838   14.181209    0.896760   \n",
       "min     892.000000    0.000000    1.000000    0.170000    0.000000   \n",
       "25%     996.250000    0.000000    1.000000   21.000000    0.000000   \n",
       "50%    1100.500000    0.000000    3.000000   27.000000    0.000000   \n",
       "75%    1204.750000    1.000000    3.000000   39.000000    1.000000   \n",
       "max    1309.000000    1.000000    3.000000   76.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  418.000000  417.000000  \n",
       "mean     0.392344   35.627188  \n",
       "std      0.981429   55.907576  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.895800  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.500000  \n",
       "max      9.000000  512.329200  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6cbc21f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.3)\n",
    "for titanic_indices , test_indices in split.split(data, data[[\"Survived\", \"Sex\", \"Pclass\"]]):\n",
    "    strat_titanic_set = data.loc[titanic_indices]\n",
    "    strat_test_set = data.loc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "109eaa80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.subplot(1,2,1)\n",
    "strat_titanic_set['Survived'].hist()\n",
    "strat_titanic_set['Pclass'].hist()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "strat_test_set['Survived'].hist()\n",
    "strat_test_set['Pclass'].hist()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "734e07d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 292 entries, 307 to 302\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  292 non-null    int64  \n",
      " 1   Survived     292 non-null    int64  \n",
      " 2   Pclass       292 non-null    int64  \n",
      " 3   Name         292 non-null    object \n",
      " 4   Sex          292 non-null    object \n",
      " 5   Age          227 non-null    float64\n",
      " 6   SibSp        292 non-null    int64  \n",
      " 7   Parch        292 non-null    int64  \n",
      " 8   Ticket       292 non-null    object \n",
      " 9   Fare         292 non-null    float64\n",
      " 10  Cabin        64 non-null     object \n",
      " 11  Embarked     292 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 29.7+ KB\n"
     ]
    }
   ],
   "source": [
    "strat_titanic_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5417b326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin \n",
    "from sklearn.impute import SimpleImputer \n",
    "\n",
    "class AgeImputer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        imputer = SimpleImputer(strategy=\"mean\")\n",
    "        X['Age'] = imputer.fit_transform(X[['Age']])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ca56f1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "class FeatureEncoder(BaseEstimator, TransformerMixin):\n",
    "         \n",
    "        def fit(self, X, y=None) :\n",
    "            return self\n",
    "        \n",
    "        def transform(self, X) :\n",
    "            encoder =OneHotEncoder()\n",
    "            matrix = encoder.fit_transform(X[['Embarked']]).toarray()\n",
    "            \n",
    "            column_names =(\"C\", \"S\", \"Q\", \"N\")\n",
    "            \n",
    "            for i in range(len(matrix.T)):\n",
    "                X[column_names[i]] = matrix.T[i]\n",
    "                \n",
    "                matrix = encoder.fit_transform(X[['Sex']]).toarray()\n",
    "                \n",
    "                \n",
    "                column_names = [\"Female\", \"Male\"]\n",
    "                \n",
    "                for i in range(len(matrix.T)):\n",
    "                    X[column_names[i]] = matrix.T[i]\n",
    "                \n",
    "                return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1cb5246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureDropper(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.drop([\"Embarked\",  \"Name\", \"Ticket\", \"Cabin\", \"Sex\", \"N\"], axis =1, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2f1454bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline  import Pipeline\n",
    "\n",
    "pipeline = Pipeline([(\"ageimputer\", AgeImputer()),\n",
    "                     (\"featureencoder\", FeatureEncoder()),\n",
    "                     (\"featuredropper\", FeatureDropper())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c40a3c75",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Embarked'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[173], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m strat_titanic_set \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrat_titanic_set\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:437\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;124;03m\"\"\"Fit the model and transform with the final estimator.\u001b[39;00m\n\u001b[0;32m    411\u001b[0m \n\u001b[0;32m    412\u001b[0m \u001b[38;5;124;03mFits all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;124;03m    Transformed samples.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    436\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m--> 437\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps)\n\u001b[0;32m    439\u001b[0m last_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:359\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    357\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 359\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m fit_transform_one_cached(\n\u001b[0;32m    360\u001b[0m     cloned_transformer,\n\u001b[0;32m    361\u001b[0m     X,\n\u001b[0;32m    362\u001b[0m     y,\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    364\u001b[0m     message_clsname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    365\u001b[0m     message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(step_idx),\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps[name],\n\u001b[0;32m    367\u001b[0m )\n\u001b[0;32m    368\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    892\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 893\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit_transform(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    895\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 142\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    147\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    148\u001b[0m         )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py:859\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    858\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 142\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    147\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    148\u001b[0m         )\n",
      "Cell \u001b[1;32mIn[57], line 10\u001b[0m, in \u001b[0;36mFeatureEncoder.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X) :\n\u001b[0;32m      9\u001b[0m     encoder \u001b[38;5;241m=\u001b[39mOneHotEncoder()\n\u001b[1;32m---> 10\u001b[0m     matrix \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEmbarked\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[0;32m     12\u001b[0m     column_names \u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(matrix\u001b[38;5;241m.\u001b[39mT)):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3812\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3813\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3815\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6130\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   6129\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['Embarked'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "strat_titanic_set = pipeline.fit_transform(strat_titanic_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "3e2bcdb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>C</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>1199</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.3500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>1112</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.8583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>904</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>82.2667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1017</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>17.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.2250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>1206</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135.6333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>940</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.2917</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>1151</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>1029</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>26.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>1194</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>43.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>292 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass    Age  SibSp  Parch      Fare    C  \\\n",
       "307         1199         0       3   0.83      0      1    9.3500  0.0   \n",
       "220         1112         1       2  30.00      1      0   13.8583  1.0   \n",
       "12           904         1       1  23.00      1      0   82.2667  0.0   \n",
       "125         1017         1       3  17.00      0      1   16.1000  0.0   \n",
       "5            897         0       3  14.00      0      0    9.2250  0.0   \n",
       "..           ...       ...     ...    ...    ...    ...       ...  ...   \n",
       "314         1206         1       1  55.00      0      0  135.6333  1.0   \n",
       "48           940         1       1  60.00      0      0   76.2917  1.0   \n",
       "259         1151         0       3  21.00      0      0    7.7750  0.0   \n",
       "137         1029         0       2  26.00      0      0   13.0000  0.0   \n",
       "302         1194         0       2  43.00      0      1   21.0000  0.0   \n",
       "\n",
       "     Female  Male  \n",
       "307     0.0   1.0  \n",
       "220     1.0   0.0  \n",
       "12      1.0   0.0  \n",
       "125     1.0   0.0  \n",
       "5       0.0   1.0  \n",
       "..      ...   ...  \n",
       "314     1.0   0.0  \n",
       "48      1.0   0.0  \n",
       "259     0.0   1.0  \n",
       "137     0.0   1.0  \n",
       "302     0.0   1.0  \n",
       "\n",
       "[292 rows x 10 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_titanic_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "05b04cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 292 entries, 307 to 302\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  292 non-null    int64  \n",
      " 1   Survived     292 non-null    int64  \n",
      " 2   Pclass       292 non-null    int64  \n",
      " 3   Age          292 non-null    float64\n",
      " 4   SibSp        292 non-null    int64  \n",
      " 5   Parch        292 non-null    int64  \n",
      " 6   Fare         292 non-null    float64\n",
      " 7   C            292 non-null    float64\n",
      " 8   Female       292 non-null    float64\n",
      " 9   Male         292 non-null    float64\n",
      "dtypes: float64(5), int64(5)\n",
      "memory usage: 25.1 KB\n"
     ]
    }
   ],
   "source": [
    "strat_titanic_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ed736c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = strat_titanic_set.drop(['Survived'], axis=1)\n",
    "y = strat_titanic_set['Survived']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_data = scaler.fit_transform(X)\n",
    "y_data = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "103b3626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-21 {color: black;background-color: white;}#sk-container-id-21 pre{padding: 0;}#sk-container-id-21 div.sk-toggleable {background-color: white;}#sk-container-id-21 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-21 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-21 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-21 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-21 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-21 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-21 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-21 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-21 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-21 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-21 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-21 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-21 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-21 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-21 div.sk-item {position: relative;z-index: 1;}#sk-container-id-21 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-21 div.sk-item::before, #sk-container-id-21 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-21 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-21 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-21 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-21 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-21 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-21 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-21 div.sk-label-container {text-align: center;}#sk-container-id-21 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-21 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-21\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
       "             param_grid=[{&#x27;max_depth&#x27;: [2, 5, 10],\n",
       "                          &#x27;min_samples_split&#x27;: [2, 3, 4],\n",
       "                          &#x27;n_estimators&#x27;: [10, 100, 200, 500]}],\n",
       "             return_train_score=True, scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
       "             param_grid=[{&#x27;max_depth&#x27;: [2, 5, 10],\n",
       "                          &#x27;min_samples_split&#x27;: [2, 3, 4],\n",
       "                          &#x27;n_estimators&#x27;: [10, 100, 200, 500]}],\n",
       "             return_train_score=True, scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
       "             param_grid=[{'max_depth': [2, 5, 10],\n",
       "                          'min_samples_split': [2, 3, 4],\n",
       "                          'n_estimators': [10, 100, 200, 500]}],\n",
       "             return_train_score=True, scoring='accuracy')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "param_gird = [\n",
    "    {\"n_estimators\": [10, 100, 200, 500], \"max_depth\": [2, 5, 10], \"min_samples_split\": [2,3,4]}\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_gird,  cv=3, scoring=\"accuracy\", return_train_score=True)\n",
    "grid_search.fit(X_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fa9e5172",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3b245b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-22 {color: black;background-color: white;}#sk-container-id-22 pre{padding: 0;}#sk-container-id-22 div.sk-toggleable {background-color: white;}#sk-container-id-22 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-22 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-22 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-22 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-22 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-22 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-22 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-22 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-22 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-22 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-22 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-22 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-22 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-22 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-22 div.sk-item {position: relative;z-index: 1;}#sk-container-id-22 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-22 div.sk-item::before, #sk-container-id-22 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-22 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-22 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-22 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-22 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-22 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-22 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-22 div.sk-label-container {text-align: center;}#sk-container-id-22 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-22 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-22\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=2, n_estimators=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" checked><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=2, n_estimators=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=2, n_estimators=10)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c6f47c90",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Embarked'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[131], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m strat_test_set \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrat_test_set\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:437\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;124;03m\"\"\"Fit the model and transform with the final estimator.\u001b[39;00m\n\u001b[0;32m    411\u001b[0m \n\u001b[0;32m    412\u001b[0m \u001b[38;5;124;03mFits all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;124;03m    Transformed samples.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    436\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m--> 437\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps)\n\u001b[0;32m    439\u001b[0m last_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:359\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    357\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 359\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m fit_transform_one_cached(\n\u001b[0;32m    360\u001b[0m     cloned_transformer,\n\u001b[0;32m    361\u001b[0m     X,\n\u001b[0;32m    362\u001b[0m     y,\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    364\u001b[0m     message_clsname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    365\u001b[0m     message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(step_idx),\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps[name],\n\u001b[0;32m    367\u001b[0m )\n\u001b[0;32m    368\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    892\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 893\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit_transform(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    895\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 142\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    147\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    148\u001b[0m         )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py:859\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    858\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 142\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    147\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    148\u001b[0m         )\n",
      "Cell \u001b[1;32mIn[57], line 10\u001b[0m, in \u001b[0;36mFeatureEncoder.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X) :\n\u001b[0;32m      9\u001b[0m     encoder \u001b[38;5;241m=\u001b[39mOneHotEncoder()\n\u001b[1;32m---> 10\u001b[0m     matrix \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEmbarked\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[0;32m     12\u001b[0m     column_names \u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(matrix\u001b[38;5;241m.\u001b[39mT)):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3812\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3813\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3815\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6130\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   6129\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['Embarked'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "strat_test_set = pipeline.fit_transform(strat_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c43be612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>C</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>1121</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>943</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1082</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>1095</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1064</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1288</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>980</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>29.787333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>1159</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29.787333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.5500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>1253</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0042</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass        Age  SibSp  Parch     Fare    C  \\\n",
       "229         1121         0       2  36.000000      0      0  13.0000  0.0   \n",
       "51           943         0       2  27.000000      0      0  15.0333  1.0   \n",
       "190         1082         0       2  34.000000      1      0  26.0000  0.0   \n",
       "203         1095         1       2   8.000000      1      1  26.0000  0.0   \n",
       "172         1064         0       3  23.000000      1      0  13.9000  0.0   \n",
       "..           ...       ...     ...        ...    ...    ...      ...  ...   \n",
       "396         1288         0       3  24.000000      0      0   7.2500  0.0   \n",
       "88           980         1       3  29.787333      0      0   7.7500  0.0   \n",
       "161         1053         0       3   7.000000      1      1  15.2458  1.0   \n",
       "267         1159         0       3  29.787333      0      0   7.5500  0.0   \n",
       "361         1253         1       2  24.000000      1      1  37.0042  1.0   \n",
       "\n",
       "     Female  Male  \n",
       "229     0.0   1.0  \n",
       "51      0.0   1.0  \n",
       "190     0.0   1.0  \n",
       "203     1.0   0.0  \n",
       "172     0.0   1.0  \n",
       "..      ...   ...  \n",
       "396     0.0   1.0  \n",
       "88      1.0   0.0  \n",
       "161     0.0   1.0  \n",
       "267     0.0   1.0  \n",
       "361     1.0   0.0  \n",
       "\n",
       "[126 rows x 10 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f22d3f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = strat_test_set.drop(['Survived'], axis=1)\n",
    "y_test = strat_test_set['Survived']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_data_test = scaler.fit_transform(X_test)\n",
    "y_data_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "eb1d665b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[168], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfinal_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_data_test\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_data_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py:649\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;124;03mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[0;32m    626\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    645\u001b[0m \u001b[38;5;124;03m    Mean accuracy of ``self.predict(X)`` wrt. `y`.\u001b[39;00m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m--> 649\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(y, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:820\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    800\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 820\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    823\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:862\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    860\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    861\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 862\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    865\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:602\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    601\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 602\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py:546\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 546\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    547\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    918\u001b[0m         )\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 921\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m     )\n\u001b[1;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "final_clf.score(X_data_test , y_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d156b480",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pipeline.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "edcb2d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>C</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>34.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>47.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>62.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>27.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>30.27259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>38.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>30.27259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>30.27259</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass       Age  SibSp  Parch      Fare    C  \\\n",
       "0            892         0       3  34.50000      0      0    7.8292  0.0   \n",
       "1            893         1       3  47.00000      1      0    7.0000  0.0   \n",
       "2            894         0       2  62.00000      0      0    9.6875  0.0   \n",
       "3            895         0       3  27.00000      0      0    8.6625  0.0   \n",
       "4            896         1       3  22.00000      1      1   12.2875  0.0   \n",
       "..           ...       ...     ...       ...    ...    ...       ...  ...   \n",
       "413         1305         0       3  30.27259      0      0    8.0500  0.0   \n",
       "414         1306         1       1  39.00000      0      0  108.9000  1.0   \n",
       "415         1307         0       3  38.50000      0      0    7.2500  0.0   \n",
       "416         1308         0       3  30.27259      0      0    8.0500  0.0   \n",
       "417         1309         0       3  30.27259      1      1   22.3583  1.0   \n",
       "\n",
       "     Female  Male  \n",
       "0       0.0   1.0  \n",
       "1       1.0   0.0  \n",
       "2       0.0   1.0  \n",
       "3       0.0   1.0  \n",
       "4       1.0   0.0  \n",
       "..      ...   ...  \n",
       "413     0.0   1.0  \n",
       "414     1.0   0.0  \n",
       "415     0.0   1.0  \n",
       "416     0.0   1.0  \n",
       "417     0.0   1.0  \n",
       "\n",
       "[418 rows x 10 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "50776670",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = final_data.drop(['Survived'], axis=1)\n",
    "y_final = final_data['Survived']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_data_final =scaler.fit_transform(X_final)\n",
    "y_data_final = y_final.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ffc0a09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 820, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 862, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 602, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 546, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "72 fits failed out of a total of 108.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "72 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 345, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 565, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1106, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the train scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[141], line 8\u001b[0m\n\u001b[0;32m      3\u001b[0m param_gird \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      4\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m500\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_samples_split\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m]}\n\u001b[0;32m      5\u001b[0m ]\n\u001b[0;32m      7\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(prod_clf, param_gird,  cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, return_train_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_data_final\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_data_final\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:909\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    907\u001b[0m refit_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 909\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    910\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    911\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:345\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 345\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    349\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 565\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[1;32m-> 1106\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    918\u001b[0m         )\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 921\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m     )\n\u001b[1;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "prod_clf =RandomForestClassifier()\n",
    "\n",
    "param_gird = [\n",
    "    {\"n_estimators\": [10, 100, 200, 500], \"max_depth\": [2, 5, 10], \"min_samples_split\": [2,3,4]}\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(prod_clf, param_gird,  cv=3, scoring=\"accuracy\", return_train_score=True)\n",
    "grid_search.fit(X_data_final, y_data_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6d60b2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_final_clf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a5d874ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6648e022",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_data = pipeline.fit_transform(titanic_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "973e2be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final_test = final_test_data\n",
    "X_final_test - X_final_test.fillna(method=\"ffill\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_data_final_test = scaler.fit_transform(X_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "92ff29c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[176], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mprod_final_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_data_final_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:820\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    800\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 820\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    823\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:860\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    840\u001b[0m \u001b[38;5;124;03m    Predict class probabilities for X.\u001b[39;00m\n\u001b[0;32m    841\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;124;03m        classes corresponds to that in the attribute :term:`classes_`.\u001b[39;00m\n\u001b[0;32m    859\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 860\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[0;32m    862\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1390\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1385\u001b[0m     fitted \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1386\u001b[0m         v \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(estimator) \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m v\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1387\u001b[0m     ]\n\u001b[0;32m   1389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted:\n\u001b[1;32m-> 1390\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "predictions = prod_final_clf.predict(X_data_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6f31451a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[175], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m final_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(titanic_test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPassengerId\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 2\u001b[0m final_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSurvived\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpredictions\u001b[49m\n\u001b[0;32m      3\u001b[0m final_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "final_df = pd.DataFrame(titanic_test_data['PassengerId'])\n",
    "final_df['Survived'] = predictions\n",
    "final_df.to_csv(\"predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95602980",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
